---
title: "05_完全分布式搭建.md"
date: 2019-09-29 17:53:13 +0800
lastmod: 2020-02-08 12:28:55 +0800
draft: false
tags: ["hadoop"]
categories: ["大数据"]
author: "Claymore"
 
---
操作环境： mac

### 下载

1. 下载VMvare, 并破解安装
   http://www.3322.cc/soft/30553.html,

2. 下载centos 7.6 x64镜像，官网下载， dvd版。

   https://www.centos.org/download/

3. vm配置并启动镜像

   <https://blog.csdn.net/weixin_42704736/article/details/82453450>

   <https://blog.csdn.net/amberdreams/article/details/81783637>

   注意网络的配置，开始给的ip端基本是不可修改的

4. 配置ip, 解决外网问题

   ping 百度或者网关: name or service not known

   https://blog.csdn.net/yjkkkkk/article/details/78695278

   看 vmnet8的配置： `/Library/Preferences/VMware\ Fusion/vmnet8中的dhcpd.conf`

   ```json
   subnet 192.168.145.0 netmask 255.255.255.0 {
   	range 192.168.145.128 192.168.145.254;   # 虚拟机ip范围
   	option broadcast-address 192.168.145.255;
   	option domain-name-servers 192.168.145.2;
   	option domain-name localdomain;
   	default-lease-time 1800;                # default is 30 minutes
   	max-lease-time 7200;                    # default is 2 hours
   	option netbios-name-servers 192.168.145.2;
   	option routers 192.168.145.2;          # 配置默认网关
   }
   host vmnet8 {
   	hardware ethernet 00:50:56:C0:00:08;
   	fixed-address 192.168.145.1;
   	option domain-name-servers 0.0.0.0;
   	option domain-name "";
   	option routers 0.0.0.0;
   }
   ```
   
   我的/etc/sysconfig/network-scripts/ifcfg-ens33：
   
   ```json
   IPADDR="192.168.145.201"
   BOOTPROTO="static"
   ONBOOT="yes"
   GATEWAY="192.168.145.2"
   DNS1="8.8.8.8"
   DNS2="114.114.114.114"
   ```
   
   加DNS:
   
   ```
   nameserver 8.8.8.8
   nameserver 8.8.4.4
   nameserver 114.114.114.114
   ```
   
   ping badidu 测试外网
   



### hosts

更改host

`hostnamectl set-hostname node201` 

`bash` 更新命令行前缀



```
[root@node201 ~]# cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6

192.168.145.201 node201
192.168.145.202 node202
192.168.145.203 node203
```





### 配置java

去官网下载

mkdir -p /opt/module

tar xvfz dk-8u211-linux-x64.tar.gz -C /opt/module



添加环境变量：

```shell
vim /etc/profile
export JAVA_HOME=/opt/module/jdk1.8.0_211
export PATH=$PATH:$JAVA_HOME/bin

# 使环境变量生效
source /etc/profile

# 验证：
[root@node101 ~]# java -version
java version "1.8.0_211"
Java(TM) SE Runtime Environment (build 1.8.0_211-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode)
```

   

   

   ### 配置Hadoop

官网下载: https://hadoop.apache.org/releases.html , 注意是二进制包

   ```shell
mkdir /usr/hadoop
tar -xzvf hadoop-2.9.2.tar.gz -C /usr/hadoop

# 配置环境变量
vim /etc/profile
export HADOOP_HOME=/opt/module/hadoop-2.9.2
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

# source /etc/profile
# hadoop version
Hadoop 2.9.2
Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704
Compiled by ajisaka on 2018-11-13T12:42Z
Compiled with protoc 2.5.0
From source with checksum 3a9939967262218aa556c684d107985
This command was run using /usr/hadoop/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar
   ```

创建hdfs目录：

```shell
cd /usr/hadoop
mkdir hdfs
cd hdfs
mkdir name data tmp
/usr/hadoop/hdfs/name    --存储namenode文件
/usr/hadoop/hdfs/data      --存储数据
/usr/hadoop/hdfs/tmp       --存储临时文件
```



ps: 可以删除share/doc文件，400多M，比较占用空间。



#### 主要配置

`cd /usr/hadoop/hadoop-2.9.2/etc/hadoop/`

设置JAVA_HOME实际路径, 虽然已经设置过它的环境变量，但是在hadoop2中还是要再设置一遍，否则在启动时会提示找不到：

```shell
vi hadoop-env.sh

#export JAVA_HOME=${JAVA_HOME}
export JAVA_HOME=/opt/module/jdk1.8.0_211

# hadoop 3 中还要配置角色：
export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SENCONDARYNAMENODE_USER=root

vi yarn-env.sh
# export JAVA_HOME=/home/y/libexec/jdk1.6.0/
export JAVA_HOME=/opt/module/jdk1.8.0_211
```



core-site.xml:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
 <!--这个配置意思是设置master节点信息-->
 <property>
  <name>fs.defaultFS</name>
  <value>hdfs://node201:8020</value>
 </property>
 <!--这个配置意思是设置hadoop的工作目录，包括索引数据和真实数据的存储位置-->
 <property>
  <name>hadoop.tmp.dir</name>
  <value>/usr/hadoop/hdfs/tmp</value>
 </property>
</configuration>
```



hdfs-site.xml:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>　　 
  <property>
    <!--配置hdfs的块存储默认副本数-->
    <name>dfs.replication</name> 　　　　 
    <value>3</value> 　　
  </property> 　　 
  <property>　　　　 
    <name>dfs.name.dir</name> 　　　　 
    <value>/usr/hadoop/hdfs/name</value> 　　
  </property> 　　 
  <property>　　　　 
    <name>dfs.data.dir</name> 　　　　 
    <value>/usr/hadoop/hdfs/data</value> 　　
  </property> 　　 
  <property>　　　　 
    <name>dfs.permissions</name> 　　　　 
    <value>false</value> 　　
  </property> 
</configuration>
```

dfs.permissions：默认值为true，设置为true有时候会遇到数据因为权限访问不了；设置为false可以不要检查权限就生成dfs上的文件



mapred-site.xml
cp mapred-site.xml.template mapred-site.xml

```xml
<configuration>
　　<property>
　　　　<name>mapreduce.framework.name</name>
　　　　<value>yarn</value>
　　</property>
</configuration>
```

mapreduce.framework.name：指定mapreduce运行在yarn平台，默认为local



yarn-site.xml

```xml
<configuration>
　　<property>
　　　　<name>yarn.resourcemanager.hostname</name>
　　　　<value>node201</value>
　　</property>
　　<property>
　　　　<name>yarn.nodemanager.aux-services</name>
　　　　<value>mapreduce_shuffle</value>
　　</property>
　　<property>
　　　　<name>yarn.nodemanager.vmem-check-enabled</name>
　　　　<value>false</value>
　　</property>
</configuration>
```

yarn.resourcemanager.hostname：指定yarn的resourcemanager的地址

yarn.nodemanager.aux-services：reducer获取数据的方式

yarn.nodemanager.vmem-check-enabled：意思是忽略虚拟内存的检查，如果安装在虚拟机上，这个配置很有用，配上去之后后续操作不容易出问题。如果是在实体机上，并且内存够多，可以将这个配置去掉



slaves( 3.0 之后叫workers)

```
node202
node203
```



#### 其他配置

所有主机关闭防火墙并禁止其开机自启：

```
systemctl stop firewalld
systemctl disable firewalld
```

将SELinux status参数设定为关闭状态

```sh
[root@localhost hadoop]# /usr/sbin/sestatus
SELinux status:                 enabled
SELinuxfs mount:                /sys/fs/selinux
SELinux root directory:         /etc/selinux
Loaded policy name:             targeted
Current mode:                   enforcing
Mode from config file:          enforcing
Policy MLS status:              enabled
Policy deny_unknown status:     allowed

# 1、临时关闭（不用重启机器）：
setenforce 0                  
##设置SELinux 成为permissive模式
##setenforce 1 设置SELinux 成为enforcing模式

# 2、修改配置文件需要重启机器：
修改/etc/selinux/config 文件
将SELINUX=enforcing改为SELINUX=disabled

$sudo /usr/sbin/sestatus 
SELinux status:                 disabled
```

配置后重启



201到其他节点免登录：

```
[centos@node101 ~]$ssh-keygen -t rsa
[centos@node101 ~]$ ssh-copy-id node101
[centos@node101 ~]$ ssh-copy-id node102
[centos@node101 ~]$ ssh-copy-id node103
```



#### 启动

copy整个/usr/hadoop/目录到其它机器

scp -r hadoop root@node202:/usr/

scp -r hadoop root@node203:/usr/



启动之前需要格式化一下。因为node201是namenode，node202和node203都是datanode，所以在node201上运行 

`hadoop namenode -format`

可以看到在/usr/hadoop/hdfs/name目录下多了一个current目录

 `start-all.sh`:

```
[root@node201 hadoop]# start-all.sh
This script is Deprecated. Instead use start-dfs.sh and start-yarn.sh
Starting namenodes on [node201]
node201: starting namenode, logging to /usr/hadoop/hadoop-2.9.2/logs/hadoop-root-namenode-node201.out
node202: starting datanode, logging to /usr/hadoop/hadoop-2.9.2/logs/hadoop-root-datanode-node202.out
node203: starting datanode, logging to /usr/hadoop/hadoop-2.9.2/logs/hadoop-root-datanode-node203.out
Starting secondary namenodes [0.0.0.0]
0.0.0.0: starting secondarynamenode, logging to /usr/hadoop/hadoop-2.9.2/logs/hadoop-root-secondarynamenode-node201.out
starting yarn daemons
starting resourcemanager, logging to /usr/hadoop/hadoop-2.9.2/logs/yarn-root-resourcemanager-node201.out
node202: starting nodemanager, logging to /usr/hadoop/hadoop-2.9.2/logs/yarn-root-nodemanager-node202.out
node203: starting nodemanager, logging to /usr/hadoop/hadoop-2.9.2/logs/yarn-root-nodemanager-node203.out
[root@node201 hadoop]#
```

主节点node201执行jps:

```
[root@node201 hadoop]# jps
10529 NameNode
10722 SecondaryNameNode
11143 Jps
10877 ResourceManager
```

其他节点：

```
[root@node202 ~]# jps
8100 Jps
7849 DataNode
7934 NodeManager
```



#### 访问

hdfs管理页： http://192.168.145.201:50070/

Yarn 管理页： http://192.168.145.201:8088/



参考： https://blog.csdn.net/sjmz30071360/article/details/79889055





#### 其他命令

stop-all.sh 停止所有的Hadoop守护进程

https://www.cnblogs.com/xym4869/p/8821312.html