Tags:[python]

## 文件操作

###  创建文件

​      `对象名 = open(文件名，模式)`
​      一般用f来指代文件对象

常用的模式：

#### 模式

* r 打开只读文件，该文件必须存在。

- r+ 打开可读写的文件，该文件必须存在。

- w 打开只写文件，若文件存在则文件长度清为0，即该文件内容会消失。

  若文件不存在则 建立该文件。

- w+ 打开可读写文件，若文件存在则文件长度清为零，即该文件内容会消失。

  若文件不存在则建立该文件。

- a 以附加**写**的方式打开只写文件。若文件不存在，则会建立该文件，如果文件存在，写入的数据会被加到文件尾，即文件原先的内容会被保留。

- a+ 以附加**读写**方式打开可读写的文件。若文件不存在，则会建立该文件，如果文件存在，写入的数据会被加到文件尾后，即文件原先的内容会被保留。

上述的形态字符串都可以再加一个b字符，如rb、w+b或ab＋等组合，加入b 字符用来告诉函数库打开的文件为二进制文件，而非纯文字文件。windows下文件是二进制，而linux不需要区分二进制和文件。

关闭文件：

`f.close()`



#### 读取

设文件内容：

```
aa
bb
cc
dd
```

读取：

```python
>>> content1 = f.read(N)          # 读取N bytes的数据, 没有指定N,默认所有
'aa\nbb\ncc\ndd\n'

>>> content2 = f.readline()       # 读取一行
'aa\n'

>>> content3 = f.readlines()      # 读取所有行，储存在列表中，每个元素是一行。
['aa\n', 'bb\n', 'cc\n', 'dd\n']

>>> content1.splitlines()         # 去掉空格， 注意这里是centent1
['aa', 'bb', 'cc', 'dd']
```

循环读取：

```python
with open("file", "r") as fd:
    for line in fd:
        line = line.strip()
```





#### 写入

`f.write('I like apple!\n')      # 将'I like apple'写入文件并换行`

`f.writelines(['a\n', 'b\n', 'c\n'])`   注意一定要加换行，不然只写了一行  

- 关闭文件

- 指定编码

  ```python
  open('cafe.txt', 'w', encoding='utf-8').write()  
  ```



### 上下文管理器

先看两段程序： 

```python
# without context manager
f = open("new.txt", "w")
print(f.closed)               # whether the file is open
f.write("Hello World!")
f.close()
print(f.closed)
```

用上下文管理器：

```python
# with context manager
with open("new.txt", "w") as f:
    print(f.closed)
    f.write("Hello World!")
print(f.closed)
```

两段程序是相同的操作，但是第二段程序没有关闭文件的链接，只是用**缩进**
和`with...as..`上下文管理来规定了对象的使用范围。
对于文件对象f来说，它定义了`__enter__()`和`__exit__()`方法(可以通过dir(f)看到)。在f的`__exit__()`方法中，有self.close()语句。所以在使用上下文管理器时，我们就不用明文关闭f文件了。



上下文管理器协议包含`__enter__` 和 `__exit__` 两个方法。 

with 语句开始运行时， 会在上下文管理器对象上调用`__enter__` 方法。

with 语句运行结束后，会在上下文管理器对象上调用`__exit__` 方法。



with 的as语句是可选的，但对open函数来说必须加上as字句，以便获取文件的引用。

不管控制流程以哪种方式退出with 块， 都会在上下文管理器上调用`__exit__` 方法，  而不是在`__enter__` 方法返回的对象上调用。

```python
class WithClass:

    def __enter__(self): # 除了隐式的self， 不会传入任何参数。
        return 'ABCD'

    def __exit__(self, exc_type, exc_value, traceback): 
        if exc_type is ZeroDivisionError:
            print 'please do not divide by zero'
            return True
        print exc_type,'---', exc_value, '---', traceback
        return True

with WithClass() as what:
    print 'in'
    a=0
    #a+='1'
    print 'behind error'

print what
# out:
in
behind error
None --- None --- None
ABCD
# 把a+='1'注释打开：
in
<type 'exceptions.TypeError'> --- unsupported operand type(s) for +=: 'int' and 'str' --- <traceback object at 0x10e860098>
ABCD
```

`__exit__` 的三个参数是异常类，异常实例，traceback对象。try中用sys.exc_info()得到的就是这三个对象。



#### 获取某函数的print到变量

```python
from cStringIO import StringIO
import sys

class Capturing(list):
    def __enter__(self):
        self._stdout = sys.stdout
        sys.stdout = self._stringio = StringIO()
        return self
    def __exit__(self, *args):
        self.extend(self._stringio.getvalue().splitlines())
        del self._stringio    # free up some memory
        sys.stdout = self._stdout
```

Usage:

```
with Capturing() as output:
    do_something(my_object)
```



这时do_something函数中的print不会真正的输出，它的输出都会存放在output中，

获得输出我们只需要其output变量就好。



### 输出重定向到文件

```python
import os
import sys

temp=sys.stdout # 记录当前输出指向，默认是consle

with open("outputlog.txt","a+") as f:
    sys.stdout=f   # 输出指向txt文件
    print("filepath:",__file__,
    "\nfilename:",os.path.basename(__file__))
    print("some other information")
    print("some other")
    print("information")
    sys.stdout=temp # 输出重定向回consle
    print(f.readlines()) # 将记录在文件中的结果输出到屏幕
```





### 大文件的处理

一般的读取文件的方法：

```python
with open(file_path, "r") as f:
　　print f.read()
或者
with open(file_path,"r") as f:
　　for line in f.readlines():
　　　　print line
```

read()是一次性把文件内容以字符串的方式读到内存，放到一个字符串变量中

readlines() 是一次性读取所有内容，并按行生成一个list

因一次性读取，若文件内容过大，则会将内存爆掉。

**报错：“MemoryError”**



#### 自带处理

 利用open("","")系统自带方法生成的迭代对象

```python
with open(file_path) as f:
	for line in f:
		print line
```

for line in f 这种用法是把文件对象f当作迭代对象，系统将自动处理IO缓存和内存管理。



#### 生成器

用生成器配合read(size),  构造一个生成器，size可以自己指定大小

```python
def dakai():
	with open("log.log","r",encoding="utf-8") as f:
       while 1:
             data=f.read(1024)
             if not data:break
             yield data
```

接下来遍历生成器就好了，没试过这么大文件，想必这是又稳妥又简单的方法之一。



#### 统计行数

如果统计一个大文件的行数，可以巧用内置enumerate函数，是个生成器，几个g的txt文档一样ok。

```python
count=0
for index,line in enumerate(open("name.txt","r",encoding="utf8")):
   count+=1
```

