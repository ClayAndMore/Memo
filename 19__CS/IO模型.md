---
title: "IO模型.md"
date: 2017-04-27 17:53:13 +0800
lastmod: 2019-09-29 17:53:13 +0800
draft: false
tags: [""]
categories: ["网络原理"]
author: "Claymore"

---


### 一些概念

#### 虚拟地址

什么是虚拟地址和物理地址： 
首先，要说虚拟地址就要先说一下物理地址。可以理解我们的主存被组织成一个由M个连续的字节大小的单元组成的数组。

而每一个字节都有一个对应的地址，这样的地址就被称作是物理地址。

那么，我们的程序是不是可以直接可以接触到物理地址，就是是不是可以直接从物理地址当中获取数据。答案明显是不是的，我们先来分析一下如果所有的进程直接访问同一块连续的物理地址有什么弊端呢？ 

1. 主存的容量有限。虽然我们现在的主存容量在不断上升，4G，8G，16G的主存都出现在市面上。但是我们的进程是无限，如果计算机上的每一个进程都独占一块物理存储器(即物理地址空间)。那么，主存就会很快被用完。但是，实际上，每个进程在不同的时刻都是只会用同一块主存的数据，这就说明了其实只要在进程想要主存数据的时候我们把需要的主存加载上就好，换进换出。针对这样的需求，直接提供一整块主存的物理地址就明显不符合。 
2. 进程间通信的需求。如果每个进程都 独占一块物理地址，这样就只能通过socket这样的手段进行进程通信，但如果进程间能使用同一块物理地址就可以解决这个问题。 
3. 主存的保护问题。对于主存来说，需要说明这段内存是可读的，可写的，还是可执行的。针对这点，光用物理地址也是很难做到的。 


针对物理地址的直接映射的许多弊端，计算机的设计中就采取了一个虚拟化设计，就是虚拟内存。

**CPU通过发出虚拟地址，虚拟地址再通过MMU翻译成物理地址，最后获得数据**

对于32位的计算机，每一个地址所对应的数据空间是32位，也就是四个字节。那么如果一个地址可以用32位表示，那么对于这32位地址的所有可能就是:2的32次方种可能，那么32位地址的地址空间就为2的32次方

这便是虚拟存储器 的原理



#### 用户空间和内核空间

现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。

**操作系统的核心是内核，独立于普通应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。**

为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操作系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。

针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。

前三G是用户空间，后一G是内核空间。



#### 进程切换

为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。

从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化：

> 1. 保存处理机上下文，包括程序计数器和其他寄存器。
> 2. 更新PCB信息。
> 3. 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。
> 4. 选择另一个进程执行，并更新其PCB。
> 5. 更新内存管理的数据结构。
> 6. 恢复处理机上下文。



#### 进程阻塞

正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。

当进程进入阻塞状态，是不占用CPU资源的。



#### 文件描述符

文件描述符（File descriptor）是计算机科学中的一个术语，**是一个用于表述指向文件的引用的抽象化概念**。

文件描述符在形式上是一个非负整数。

实际上，**它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表**。

当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。

在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。



#### 缓存IO

缓存 IO 又被称作标准 IO，大多数文件系统的默认 IO 操作都是缓存 IO。

在 Linux 的缓存 IO 机制中，操作系统会将 IO 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，

**数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。**



数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。





### 异步IO

#### 何为异步

先谈下什么为异步：

有三个任务正常按时间顺序执行：

![](http://claymore.wang:5000/uploads/big/21d571b2aa23554479920de566d386ec.png)

多线程去做：

![](http://claymore.wang:5000/uploads/big/acf0273d438bee621f1ae2ab3f16e717.png)

异步去做：

![](http://claymore.wang:5000/uploads/big/827dc6526464aac1402de21c4e777c9b.png)

首先，你要知道，一个任务，可能会堵塞在某个地方，比如硬盘读写，数据库操作等等，这样一个程序就必须等待你的操作完成，才能继续下去，这无疑是对计算资源的极大浪费:（下面的图就是同步IO了）

![](http://claymore.wang:5000/uploads/big/59004ab6a895a85b654181e1cbd82dab.png)

那么如果，你在堵塞的时候，用某种机制，能使你快速脱离堵塞的状态，开启下一个程序，等待你的操作完成，在来继续上一个程序的工作，这个模型就是不堵塞的，这样资源的到了极大的利用，我们的效率自然提升.

异步IO。当代码需要执行一个耗时的IO操作时，它只发出IO指令，并不等待IO结果，然后就去执行其他代码了。一段时间后，当IO返回结果时，再通知CPU进行处理。



#### 在理解并发和并行

系统中有多个任务同时存在可称之为“并发”，系统内有多个任务同时执行可称之为“并行”；

并发是并行的子集。

比如在单核CPU系统上，只可能存在并发而不可能存在并行。上面的异步是就说明了单核的并发。

多核：

并行： 就是等于号

并发： 就是大于号

通俗点说 并发就是不同线程同时干一件事情
并行就是不同线程同时干不同的事情

所以并发会引起资源的竞争。





### 阻塞和非阻塞

阻塞是：

调用结果返回之前，当前线程会被挂起，只有调用函数得到结果后才返回。

有人会把这个概念和同步联系起来，但是他俩是不同的：

同步是当前线程是激活的，只是从逻辑上当前函数没有返回而已。 例如，我们在socket中调用recv函数，如果缓冲区中没有数据，这个函数就会一直等待，直到有数据才返回。而此时，当前线程还会继续处理各种各样的消息



非阻塞是：

调用结果返回之前，就是不能立刻得到结果之前，不会阻塞当前线程，而是立刻返回（返回一些状态，告诉你我数据还没准备好）



#### 总结

同步：调用一个函数，没有返回数据前，我死等结果。

异步：调用一个函数，有结果再通知我。

阻塞： 我没有得到数据前，不会返回。

非阻塞： 有没有结果我都立即返回，没有的话，我一会再来。



### Linux下的五种IO模型

**网络IO的本质是socket的读取，socket在linux系统被抽象为流，IO可以理解为对流的操作**。

刚才说了，对于一次IO访问（以read举例），

**数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间**。

所以说，当一个read操作发生时，它会经历两个阶段：

> 1. 第一阶段：等待数据准备 (Waiting for the data to be ready)。
> 2. 第二阶段：将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)。

对于socket流而言，

> 1. 第一步：通常涉及等待网络上的数据分组到达，然后被复制到内核的某个缓冲区。
> 2. 第二步：把数据从内核缓冲区复制到应用进程缓冲区。

我们 第一次接触到的网络编程都是从 listen()、send()、recv(接收数据),recvfrom（等待接收数据）等接口开始的。

网络应用需要处理的无非就是两大类问题，`网络IO，数据计算`。相对于后者，网络IO的延迟，给应用带来的性能瓶颈大于后者。网络IO的模型大致有如下几种：



* 阻塞I/O

  应用程序调用一个IO函数，导致应用程序阻塞，等待数据准备好。 如果数据没有准备好，一直等待….数据准备好了，从内核拷贝到用户空间,IO函数返回成功指示。

  ![](http://claymore.wang:5000/uploads/big/7a4324307e4be5445c1d81fc230a8f3b.png)

  当用户进程调用了recv()/recvfrom()这个系统调用，`kernel就开始了IO的第一个阶段：准备数据`（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。`第二个阶段：当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存`，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。

* 非阻塞I/O

  当所请求的I/O操作无法完成时，**不要将进程睡眠**，而是返回一个错误。这样我们的I/O操作函数将不断的[测试](http://lib.csdn.net/base/softwaretest)数据是否已经准备好，如果没有准备好，继续测试，直到数据准备好为止。在这个不断测试的过程中，会大量的占用CPU的时间。

  ![](http://claymore.wang:5000/uploads/big/0f46b02a4dc0a51747c3350e57ef447d.png)

  也就是说非阻塞的recvform系统调用调用之后，进程并没有被阻塞，内核马上返回给进程，如果数据还没准备好，此时会返回一个error。

  进程在返回之后，可以干点别的事情，然后再发起recvform系统调用。重复上面的过程，循环往复的进行recvform系统调用。`这个过程通常被称之为轮询`。轮询检查内核数据，直到数据准备好，再拷贝数据到进程，进行数据处理。**需要注意，拷贝数据整个过程，进程仍然是属于阻塞的状态**。

  在linux下，可以通过设置socket使其变为non-blocking。

  同步非阻塞方式相比同步阻塞方式：

  优点：能够在等待任务完成的时间里干其他活了（包括提交其他任务，也就是 “后台” 可以有多个任务在同时执行）。

  缺点：任务完成的响应延迟增大了，因为每过一段时间才去轮询一次read操作，而任务可能在两次轮询之间的任意时间完成。这会导致整体数据吞吐量的降低。

* I/O复用

  **由于同步非阻塞方式需要不断主动轮询，轮询占据了很大一部分过程，轮询会消耗大量的CPU时间，而 “后台” 可能有多个任务在同时进行，人们就想到了循环查询多个任务的完成状态，只要有任何一个任务完成，就去处理它。如果轮询不是进程的用户态，而是有人帮忙就好了。那么这就是所谓的 “IO 多路复用”。**

  多路复用的特点是**通过一种机制一个进程能同时等待IO文件描述符**，内核监视这些文件描述符（套接字描述符），其中的任意一个进入读就绪状态，select， poll，epoll函数就可以返回。对于监视的方式，又可以分为 select， poll， epoll三种方式。

  I/O复用模型会用到select、poll、epoll函数，这几个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这两个函数可以同时阻塞多个I/O操作。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时，才真正调用I/O操作函数。

  监视的事情交给了内核，内核负责数据到达的处理。也可以理解为"非阻塞"吧

  ![](http://claymore.wang:5000/uploads/big/b7048c540299d690e333ec02502679a0.png)

  **当用户进程调用了select，那么整个进程会被block**，而同时，kernel会“监视”所有select负责的socket，**任何一个socket中的数据准备好了，select就会返回**。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。

  **从整个IO过程来看，他们都是顺序执行的，因此可以归为同步模型(synchronous)。都是进程主动等待且向内核检查状态。**

  `高并发的程序一般使用同步非阻塞方式而非多线程 + 同步阻塞方式`。要理解这一点，首先要扯到并发和并行的区别。比如去某部门办事需要依次去几个窗口，`办事大厅里的人数就是并发数，而窗口个数就是并行度`。也就是说`并发数是指同时进行的任务数（如同时服务的 HTTP 请求）`，而`并行数是可以同时工作的物理资源数量（如 CPU 核数）`。通过合理调度任务的不同阶段，并发数可以远远大于并行度，这就是区区几个 CPU 可以支持上万个用户并发请求的奥秘。在这种高并发的情况下，为每个任务（用户请求）创建一个进程或线程的开销非常大。`而同步非阻塞方式可以把多个 IO 请求丢到后台去，这就可以在一个进程里服务大量的并发 IO 请求`。

  

* 信号驱动I/O

  首先我们允许套接口进行信号驱动I/O,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。

  ![](http://claymore.wang:5000/uploads/big/70c2ec32cfffbebaa931d22db94349a0.png)

* 异步IO模型

  相对于同步IO，异步IO不是顺序执行。用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情。等到socket数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知。IO两个阶段，进程都是非阻塞的。

  Linux提供了AIO库函数实现异步，但是用的很少。目前有很多开源的异步IO库，例如libevent、libev、libuv。

  当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者的输入输出操作, **在 Linux 中，通知的方式是 “信号”**

  ![](http://claymore.wang:5000/uploads/big/f560f80a31ce02870c52e932cca9046c.png)

  异步 API 说来轻巧，做来难，这主要是对 API 的实现者而言的。

  Linux 的异步 IO（AIO）支持是 2.6.22 才引入的，还有很多系统调用不支持异步 IO。

  Linux 的异步 IO 最初是为数据库设计的，`因此通过异步 IO 的读写操作不会被缓存或缓冲，这就无法利用操作系统的缓存与缓冲机制`。

  需要指出的是，虽然 Linux 上的 IO API 略显粗糙，但每种编程框架都有封装好的异步 IO 实现。

  

五种io模型的比较：

![](http://claymore.wang:5000/uploads/big/bb762f1649c77313bad5187746f62194.png)



摘自： https://www.jianshu.com/p/486b0965c296
