tags:[python, spider]

爬虫时会有反爬虫封ip的情况，针对这种情况，我们需要设置代理。

### 代理

如 requests， urllib， Selenium等，都有设置代理的方式。







### 代理池的维护

代理不论是免费的还是忖费的，都不能保证都是可用的，

因为可能 此IP 被其他人使用来爬取同样的目标站点而被封禁，或者代理服务器突然发生故障或网络繁忙
旦我们选用了一个不可用的代理，这势必会影响爬虫的工作效率。
所以，我们需要提前做筛选，将不可用的代理剔除掉，保留可用代理 接下来我 就搭建 个高
效易用的代理池。

我们需要做到下面的几个目标，来实现易用高效的 理池
基本模块分为 块：存储模块、获取模块、检测模块、接口模块

* 存储模块： 存储代理，保证代理不重复，标识代理可用
* 获取模块， 定时在各大代理网站抓取代理。
* 检测模块， 定时检测数据库中的代理， 可针对网站划分，如我们设置一个通用代理，可以用病毒链接来检测该代理的可用性，如果有时好用有时不可用，我们可以为其设置一个分数，100分可用，检测一次不可用就减一分，当分数为零，从数据库中删除。
* 接口模块，配置一个和数据库交互的接口，即拿即用。

```
获取模块 ——> 存储模块  <——> 检测模块
             |
             |
            接口模块
```

