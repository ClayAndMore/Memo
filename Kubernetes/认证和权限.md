---

title: "认证和权限.md"
date: 2020-03-24 09:58:51 +0800
lastmod: 2020-03-24 09:58:51 +0800
draft: false
tags: [""]
categories: ["k8s"]
author: "Claymore"

---



K8S 中几乎所有的操作都需要经过 `kube-apiserver` 处理，所以为了安全起见，K8S 为它提供了三类安全访问的措施。分别是：

* 用于识别用户身份的认证（Authentication）
* 用于控制用户对资源访问的授权（Authorization）
* 资源管理方面的准入控制（Admission Control）



```
      +--------------+                                         +-----------+
      |              |                                         |           |
      |    Client    |                                         |  Others   |
      |              |                                         |           |
      +------+-------+                                         +------+----+
             |                                                        |
+---------------------------------------------------------------------------+
             |                                                        |
|            v                                                        v     |
|   +--------+---------+   +----------------+   +--------------+   +--+---+ |
|   |                  |   |                |   | Admission    |   |      | |
+-> | Authentication   +-> | Authorization  +-> | Control      +-> |Logic | |
|   |                  |   |                |   |              |   |      | |
|   +------------------+   +----------------+   +--------------+   +------+ |
|                                                                           | 
|                        Kube-apiserver                                     |             
+---------------------------------------------------------------------------+  
```



### 认证

认证，无非是判断当前发起请求的用户身份是否正确。例如，我们通常登录服务器时候需要输入用户名和密码，或者 SSH Keys 之类的。

在讲认证前，我们应该先理一下 K8S 中的用户。

#### 用户

K8S 中有两类用户，一般用户及 `Service Account`。

- 一般用户：一般用户只能通过外部服务进行管理，由管理员进行私钥分发。这也意味着 K8S 中并没有任何表示一般用户的对象，所以一般用户是无法通过 API 直接添加到集群的。
- `Service Account`：由 K8S API 管理的用户，**与特定的 `NameSpace`（命名空间）绑定。**由 `API Server` 自动创建或者通过 API 手动进行创建。 同时，它会自动挂载到 `Pod` 中容器的 `/var/run/secrets/kubernetes.io/serviceaccount/` 目录中，其中会包含 `NameSpace` `token` 等信息，并允许集群内进程与 `API Server` 进行交互。

对集群操作的 API 都是与用户相关联的，或者被视为匿名请求。匿名请求可通过 `kube-apiserver` 的 `--anonymous-auth` 参数进行控制，默认是开启的，匿名用户默认的用户名为 `system:anonymous`，所属组为 `system:unauthenticated`。



#### 认证机制

- X509 客户端证书：这个认证机制我们并不陌生，我们前面搭建集群时，虽然没有指定配置文件，但 `kubeadm` 已经添加了默认参数 `--client-ca-file=/etc/kubernetes/pki/ca.crt` 而在进行认证时，将会使用客户端证书 subject 的 **`CN` 域（Common Name）用作用户名，`O` 域（Organization）用作组名。**
- 引导 Token：这个我们也不会陌生，前面我们搭建集群时，当集群通过 `kubeadm init` 初始化完成后，将会展示一行提示，其中便携带着引导 Token。如果不使用 `kubeadm` 时，需要设置 `--enable-bootstrap-token-auth=true`。
- 静态 Token 文件：启动 `Kube-apiserver` 时，设置 `--token-auth-file=SOMEFILE` 并在请求时，加上 `Authorization: Bearer TOKEN` 的请求头即可。
- 静态密码文件：与静态 Token 文件类似，设置 `--basic-auth-file=SOMEFILE` 并在请求时，加上 `Authorization: Basic BASE64ENCODED(USER:PASSWORD)` 的头即可。
- Service Account Token：这是默认启用的机制，关于 `Service Account` 前面也已经介绍过了，不再赘述。
- OpenID：其实是提供了 [OAuth2](https://link.juejin.im/?target=http%3A%2F%2Fwww.ruanyifeng.com%2Fblog%2F2014%2F05%2Foauth_2_0.html) 的认证支持，像 Azure 或 Google 这类云厂商都提供了相关支持。
- 认证代理：主要是配合身份验证代理进行使用，比如提供一个通用的授权网关供用户使用。
- Webhook：提供 Webhook 配合一个远端服务器使用。

可选择同时开启多个认证机制。比如当我们使用 `kubeadm` 创建集群时，默认便会开启 X509 客户端证书和引导 Token 等认证机制。



### 授权 Authorization

授权，也就是在验证当前发起请求的用户是否有相关的权限。例如，我们在 Linux 系统中常见的文件夹权限之类的。

授权是以认证的结果为基础的，授权机制检查用户通过认证后的请求中所包含的属性来进行判断。

K8S 支持多种授权机制，用户想要正确操作资源，则必须获得授权，**所以 K8S 默认情况下的权限都是拒绝**。当某种授权机制通过或者拒绝后，便会立即返回，不再去请求其他的授权机制；当所有授权机制都未通过时便会返回 403 错误了。



K8S 支持以下授权机制：

- ABAC(Attribute-Based Access Control)：基于属性的访问控制，在使用时需要先配置 `--authorization-mode=ABAC` 和 `--authorization-policy-file=SOME_FILENAME` 。ABAC 本身设计是非常好的，但是在 K8S 中使用却有点过于繁琐，这里不再赘述。
- RBAC(Role-based access control)：基于角色的访问控制，自 K8S 1.6 开始 beta，1.8 进入稳定版，已被大量使用。而当我们使用 `kubeadm` 安装集群的时候，默认将会添加 `--authorization-mode=Node,RBAC` 的参数，表示同时开启 `Node` 和 `RBAC` 授权机制。当然，如果你对 [MongoDB](https://link.juejin.im/?target=https%3A%2F%2Fwww.mongodb.com%2Fcn) 有所了解或者比较熟悉的话，这部分的内容就会很容易理解，因为 MongoDB 的权限控制也使用了 `RBAC` （Role-based access control）。
- Node：这是一种特殊用途的授权机制，专门用于对 `kubelet` 发出的 API 请求做授权验证。
- Webhook：使用外部的 Server 通过 API 进行授权校验，需要在启动时候增加 `--authorization-webhook-config-file=SOME_FILENAME` 以及 `--authorization-mode=Webhook`
- AlwaysAllow：默认配置，允许全部。
- AlwaysDeny：通常用于测试，禁止全部。



### 角色（Role）

上面提到了 `RBAC`，为了能更好的理解，我们需要先认识下 K8S 中的角色。K8S 中的角色从类别上主要有两类，`Role` 和 `ClusterRole`。

- `Role`：可以当作是一组权限的集合，但被限制在某个 `Namespace` 内（K8S 的 `Namespace`）。
- `ClusterRole`：对于集群级别的资源是不被 `Namespace` 所限制的，**并且还有一些非资源类的请求**，所以便产生了它。

当已经了解到角色后，剩下给用户授权也就只是需要做一次绑定即可。在 K8S 中将这一过程称之为 binding，即 `rolebinding` 和 `clusterrolebinding`。 即对应上面两种Role.

 我们来看下集群刚初始化后的情况：

role

```
[root@192.168.18.196 ~]#kubectl get roles --all-namespaces=true
NAMESPACE     NAME                                             AGE
kube-public   kubeadm:bootstrap-signer-clusterinfo             31h
kube-public   system:controller:bootstrap-signer               31h
kube-system   extension-apiserver-authentication-reader        31h
kube-system   kube-proxy                                       31h
kube-system   kubeadm:kubelet-config-1.14                      31h
kube-system   kubeadm:nodes-kubeadm-config                     31h
kube-system   system::leader-locking-kube-controller-manager   31h
kube-system   system::leader-locking-kube-scheduler            31h
kube-system   system:controller:bootstrap-signer               31h
kube-system   system:controller:cloud-provider                 31h
kube-system   system:controller:token-cleaner                  31h
```

rolebinding:

```
[root@192.168.18.196 ~]#kubectl get rolebindings --all-namespaces=true
NAMESPACE     NAME                                                AGE
kube-public   kubeadm:bootstrap-signer-clusterinfo                31h
kube-public   system:controller:bootstrap-signer                  31h
kube-system   kube-proxy                                          31h
kube-system   kubeadm:kubelet-config-1.14                         31h
kube-system   kubeadm:nodes-kubeadm-config                        31h
kube-system   system::extension-apiserver-authentication-reader   31h
kube-system   system::leader-locking-kube-controller-manager      31h
kube-system   system::leader-locking-kube-scheduler               31h
kube-system   system:controller:bootstrap-signer                  31h
kube-system   system:controller:cloud-provider                    31h
kube-system   system:controller:token-cleaner                     31h
[root@192.168.18.196 ~]#
```

同理可以看到：

kubectl get clusterroles

kubectl get clusterrolebindings



### 查看用户权限

一直都在使用 `kubectl` 对集群进行操作，那么当前用户是什么权限呢？ 对应于 `RBAC` 中又是什么情况呢？

```
[root@192.168.18.196 ~]#kubectl config view -o yaml 
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: DATA+OMITTED
    server: https://192.168.18.196:6443
  name: kubernetes
contexts:
- context:
    cluster: kubernetes
    user: kubernetes-admin
  name: kubernetes-admin@kubernetes
current-context: kubernetes-admin@kubernetes
kind: Config
preferences: {}
users:
- name: kubernetes-admin
  user:
    client-certificate-data: REDACTED
    client-key-data: REDACTED
```

14版之前用 kubectl config view users -o yaml 

`client-certificate-data` 的部分默认是不显示的，而它的**内容实际是通过 base64 加密后的证书内容**。我们可以通过通过以下方式进行查看

```
[root@192.168.18.196 ~]#kubectl config view --raw -o jsonpath='{ .users[?(@.name == "kubernetes-admin")].user.client-certificate-data}' |base64 -d  
-----BEGIN CERTIFICATE-----
....
-----END CERTIFICATE-----
[root@192.168.18.196 ~]#kubectl config view --raw -o jsonpath='{ .users[?(@.name == "kubernetes-admin")].user.client-certificate-data}' |base64 -d  |openssl x509 -text -noout 
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number: 7782067768246564933 (0x6bff7567705a7845)
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: CN=kubernetes
        Validity
            Not Before: Apr  6 10:06:03 2019 GMT
            Not After : Apr  5 10:06:05 2020 GMT
        Subject: O=system:masters, CN=kubernetes-admin
        Subject Public Key Info:
            Public Key Algorithm: rsaEncryption
           ...

```

根据前面认证部分的内容，我们知道当前的用户是 `kubernetes-admin` （CN 域），所属组是 `system:masters` （O 域） 。

我们看下 `clusterrolebindings` 中的 `cluster-admin`

```
[root@192.168.18.196 ~]#kubectl get clusterrolebindings  cluster-admin  -o yaml 
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: "true"
  creationTimestamp: "2019-04-08T04:40:12Z"
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: cluster-admin
  resourceVersion: "98"
  selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/cluster-admin
  uid: 657716d5-59b8-11e9-b92f-801844f349cc
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- apiGroup: rbac.authorization.k8s.io
  kind: Group
  name: system:masters
```

重点内容在 `roleRef` 和 `subjects` 中，名为 `cluster-admin` 的 `ClusterRole` 与名为 `system:masters` 的 `Group` 相绑定。我们继续探究下它们所代表的含义。

先看看这个 `ClusterRole` 的实际内容：

```
[root@192.168.18.196 ~]#kubectl get clusterrole cluster-admin -o yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: "true"
  creationTimestamp: "2019-04-08T04:40:11Z"
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: cluster-admin
  resourceVersion: "44"
  selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/cluster-admin
  uid: 653f6e80-59b8-11e9-b92f-801844f349cc
rules:
- apiGroups:
  - '*'
  resources:
  - '*'
  verbs:
  - '*'
- nonResourceURLs:
  - '*'
  verbs:
  - '*'
```

`rules` 中定义了它所能操作的资源及对应动作，`*` 是通配符。

到这里，我们就可以得出结论了，**当前用户 `kubernetes-admin` 属于 `system:masters` 组，而这个组与 `cluster-admin` 这个 `ClusterRole` 所绑定，所以用户也就继承了其权限。具备了对多种资源和 API 的相关操作权限**



### 创建权限可控的用户

前面是通过实际用户来反推它所具备的权限，接下来我们开始实践的部分，创建用户并为它进行授权。

我们要创建的用户名为 `backend` 所属组为 `dev`。

#### 创建namespace

为了演示，这里创建一个新的 `NameSpace` ，名为 `work`。

```
➜  ~ kubectl create namespace work
namespace/work created
➜  ~ kubectl get ns work
NAME   STATUS   AGE
work   Active   14s
```



#### 创建用户

创建私钥：

```
[root@192.168.18.196 home]#mkdir work
[root@192.168.18.196 home]#cd work/
[root@192.168.18.196 work]#openssl genrsa -out backend.key 2048
Generating RSA private key, 2048 bit long modulus
........................................................................................................................+++
................+++
e is 65537 (0x10001)
[root@192.168.18.196 work]#ls
backend.key
[root@192.168.18.196 work]#cat backend.key 
...
```



使用私钥生成证书请求：

前面已经讲过关于认证的部分，在这里需要指定 `subject` 信息，传递用户名和组名

```
[root@192.168.18.196 work]#openssl req -new -key backend.key -out backend.csr -subj "/CN=backend/O=dev"
[root@192.168.18.196 work]#ls
backend.csr  backend.key
```



使用 CA 进行签名。K8S 默认的证书目录为 `/etc/kubernetes/pki`。

```
[root@192.168.18.196 work]#openssl x509 -req -in backend.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out backend.crt -days 365
Signature ok
subject=/CN=backend/O=dev
Getting CA Private Key
[root@192.168.18.196 work]#ls
backend.crt  backend.csr  backend.key
```



查看生成的证书文件：

```
[root@192.168.18.196 work]# openssl x509 -in backend.crt -text -noout
Certificate:
    Data:
        Version: 1 (0x0)
        Serial Number:
            c1:88:a5:e6:8c:ad:a4:66
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: CN=kubernetes
        Validity
            Not Before: Apr 14 13:05:41 2019 GMT
            Not After : Apr 13 13:05:41 2020 GMT
        Subject: CN=backend, O=dev
        Subject Public Key Info:
            Public Key Algorithm: rsaEncryption
                Public-Key: (2048 bit)
                Modulus:
                    00:c7:33:9b:a0:dd:24:97:45:a6:a9:87:d9:4f:e7:
```

可以看到 `CN` 域和 `O` 域已经正确设置



#### 添加context

```
[root@192.168.18.196 work]#kubectl config set-credentials backend --client-certificate=/home/work/backend.crt  --client-key=/home/work/backend.key
User "backend" set.
[root@192.168.18.196 work]#kubectl config set-context backend-context --cluster=kubernetes --namespace=work --user=backend
Context "backend-context" created.
```



#### 使用新用户测试访问

```
[root@192.168.18.196 work]#kubectl --context=backend-context get pods
Error from server (Forbidden): pods is forbidden: User "backend" cannot list resource "pods" in API group "" in the namespace "work"

# 可能看得不够清楚，我们添加 `-v` 参数来显示详情
[root@192.168.18.196 work]#kubectl --context=backend-context get pods -n work -v 5
I0414 21:12:03.315151  187397 helpers.go:196] server response object: [{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {},
  "status": "Failure",
  "message": "pods is forbidden: User \"backend\" cannot list resource \"pods\" in API group \"\" in the namespace \"work\"",
  "reason": "Forbidden",
  "details": {
    "kind": "pods"
  },
  "code": 403
}]
F0414 21:12:03.315360  187397 helpers.go:114] Error from server (Forbidden): pods is forbidden: User "backend" cannot list resource "pods" in API group "" in the namespace "work"
```

可以看到已经使用了新的 `backend` 用户，并且默认的 `Namespace` 设置成了 `work`。





#### 添加Role

我们想要让这个用户只具备查看 `Pod` 的权限。先来创建一个配置文件。

```
[root@192.168.18.196 work]# cat <<EOF > backend-role.yaml 
> kind: Role
> apiVersion: rbac.authorization.k8s.io/v1
> metadata:
>   namespace: work
>   name: backend-role
> rules:
> - apiGroups: [""]
>   resources: ["pods"]
>   verbs: ["get", "list", "watch"]
> EOF
#  创建并查看已生成的 Role。
[root@192.168.18.196 work]#ls
backend.crt  backend.csr  backend.key  backend-role.yaml
[root@192.168.18.196 work]#kubectl create -f backend-role.yaml 
role.rbac.authorization.k8s.io/backend-role created

[root@192.168.18.196 work]#kubectl get roles  -n work -o yaml
apiVersion: v1
items:
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    creationTimestamp: "2019-04-14T13:14:11Z"
    name: backend-role
    namespace: work
    resourceVersion: "224667"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/work/roles/backend-role
    uid: 31ad7f83-5eb7-11e9-8f08-801844f349cc
  rules:
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - get
    - list
    - watch
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
```



#### 创建 Rolebinding

```
[root@192.168.18.196 work]#cat <<EOF > backend-rolebind.yaml
> kind: RoleBinding
> apiVersion: rbac.authorization.k8s.io/v1
> metadata:
>   name: backend-rolebinding          
>   namespace: work
> subjects:      
> - kind: User
>   name: backend
>   apiGroup: ""     
> roleRef:    
>   kind: Role 
>   name: backend-role
>   apiGroup: ""
> EOF
[root@192.168.18.196 work]#ls
backend.crt  backend.csr  backend.key  backend-rolebind.yaml  backend-role.yaml
[root@192.168.18.196 work]#kubectl create -f backend-rolebind.yaml
rolebinding.rbac.authorization.k8s.io/backend-rolebinding created
[root@192.168.18.196 work]#kubectl get rolebinding -o yaml -n work
apiVersion: v1
items:
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    creationTimestamp: "2019-04-14T13:16:20Z"
    name: backend-rolebinding
    namespace: work
    resourceVersion: "224833"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/work/rolebindings/backend-rolebinding
    uid: 7e733887-5eb7-11e9-8f08-801844f349cc
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: backend-role
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: backend
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

```



#### 测试用户权限

```
[root@192.168.18.196 work]#kubectl --context=backend-context get pods -n work
NAME                               READY   STATUS    RESTARTS   AGE
saythx-backend-74db8bbc87-zcqhz    1/1     Running   1          34h
saythx-frontend-5bd59fb6c4-724td   1/1     Running   0          27h
saythx-redis-75f8d49554-4g5tn      1/1     Running   1          2d2h
saythx-work-86d7cb9945-jzpvt       1/1     Running   0          27h

[root@192.168.18.196 work]#kubectl --context=backend-context get ns
Error from server (Forbidden): namespaces is forbidden: User "backend" cannot list resource "namespaces" in API group "" at the cluster scope
[root@192.168.18.196 work]#kubectl --context=backend-context get deploy -n work
Error from server (Forbidden): deployments.extensions is forbidden: User "backend" cannot list resource "deployments" in API group "extensions" in the namespace "work"
```



可以看到用户已经具备查看 `Pod` 的权限，但并不能查看 `Namespace` 或者 `deployment` 等其他资源。当然，K8S 也内置了一种很方便的调试机制。

```
➜  work kubectl auth can-i list pods -n work --as="backend"
yes
➜  work kubectl auth can-i list deploy -n work --as="backend"
no - no RBAC policy matched
```

`--as` 是一种建立在 K8S 认证机制之上的机制，可以便于系统管理员验证授权情况，或进行调试。

你也可以仿照 `~/.kube/config` 文件的内容，将当前生成的证书及私钥文件等写入到配置文件中，通过指定 `KUBECONFIG` 的环境变量，或者给 `kubectl` 传递 `--kubeconfig` 参数来使用。

也许你会觉得切换 `Namespace` 之类的操作很繁琐，有一个项目：[kubectx](https://github.com/ahmetb/kubectx) 可帮你简化这些步骤，推荐尝试。



### namespace

关于namespace 的一些补充：

当团队或项目中具有许多用户时，可以考虑使用Namespace来区分，a如果是少量用户集群，可以不需要考虑使用Namespace，如果需要它们提供特殊性质时，可以开始使用Namespace。

Namespace为名称提供了一个范围。资源的Names在Namespace中具有唯一性。

Namespace是一种将集群资源划分为多个用途(通过 [resource quota](https://kubernetes.io/docs/concepts/policy/resource-quotas/))的方法。

在未来的Kubernetes版本中，默认情况下，相同Namespace中的对象将具有相同的访问控制策略。

对于稍微不同的资源没必要使用多个Namespace来划分，例如同意软件的不同版本，可以使用[labels(标签)](http://docs.kubernetes.org.cn/247.html)来区分同一Namespace中的资源。



#### 查看

列出集群中当前的Namespace:

``` sh
kubectl get namespaces
NAME              STATUS   AGE
default           Active   24h
kube-node-lease   Active   24h
kube-public       Active   24h
kube-system       Active   24h
```

kube-system 由Kubernetes系统创建的对象的Namespace

所有对象都在 namespace 中？

**大多数Kubernetes资源（例如pod、services、replication controllers或其他）都在某些Namespace中，但Namespace资源本身并不在Namespace中**。

而低级别资源（如[Node](http://docs.kubernetes.org.cn/304.html)和persistentVolumes）不在任何Namespace中。[Events](https://www.kubernetes.org.cn/1031.html)是一个例外：它们可能有也可能没有Namespace，具体取决于[Events](https://www.kubernetes.org.cn/1031.html)的对象。



#### 创建

```
(1) 命令行直接创建
$ kubectl create namespace new-namespace

(2) 通过文件创建
$ cat my-namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: new-namespace

$ kubectl create -f ./my-namespace.yaml
```

注意：命名空间名称满足正则表达式[a-z0-9]([-a-z0-9]*[a-z0-9])?,最大长度为63位

#### 删除

```
ubectl delete namespaces new-namespace
```

注意：

1. 删除一个namespace会自动删除所有属于该namespace的资源。
2. default和kube-system命名空间不可删除。
3. PersistentVolumes是不属于任何namespace的，但PersistentVolumeClaim是属于某个特定namespace的。
4. Events是否属于namespace取决于产生events的对象。