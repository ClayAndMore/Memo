Tags:[k8s]

### 前期准备

结合 两份 02-k8s 文档来看。

关闭 Swap

查看：

```
free -h 
blkid
lsblk
```

关闭：

```
swapoff /dev/mapper/centos-swap
swapoff -a
vi /etc/fstab # 删掉有swap的那一行
```

处理后 reboot 或  mount -a



通过 `sudo cat /sys/class/dmi/id/product_uuid` 可查看机器的 `product_uuid` 请确保要搭建集群的所有节点的 `product_uuid` 均不相同。同时所有节点的 Mac 地址也不能相同，通过 `ip a` 或者 `ifconfig -a` 可进行查看。



端口情况：

 K8S 是 C/S 架构，在启动后，会固定监听一些端口用于提供服务。可以通过：

 `sudo netstat -ntlp |grep -E '6443|23[79,80]|1025[0,1,2]'` 

查看这些端口是否被占用，如果被占用，请手动释放。

在 CentOS 系统中需要通过 `sudo yum install net-tools` 安装，而在 Debian/Ubuntu 系统中，则需要通过 `sudo apt install net-tools` 进行安装。



### 安装docker

安装或并启动， 推荐docker 版本大于17.03



### 安装 kubectl kubelet kubeam

`kubectl` 是集群的客户端，我们现在搭建集群时，也必须要安装它，用于验证集群功能。

`kubeadm` 是 Kubernetes 官方提供的一个 CLI 工具，可以很方便的搭建一套符合官方最佳实践的最小化可用集群。当我们使用 `kubeadm` 搭建集群时，集群可以通过 K8S 的一致性测试，并且 `kubeadm` 还支持其他的集群生命周期功能，比如升级/降级等。

Kubelet 实现了集群中最重要的关于 Node 和 Pod 的控制功能



配置国内源：

安装kubernetes的时候，需要安装kubelet, kubeadm等包，但k8s官网给的yum源是`packages.cloud.google.com`，国内访问不了，此时我们可以使用阿里云的yum仓库镜像。

阿里云上没有附Help说明连接，简单摸索了下，如下设置可用（centos）。注意不要开启check。

```
cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF
```

* 安装 

  `yum install -y kubectl kubelet kubeadm`

* 开机启动

  `systemctl enable kubelet`

* 启动

  `systemctl start kubelet`



不过阿里云跟kubernetes同步不太及时，例如现在是1.8.1了，但是阿里云还是1.7.5。

如果你用的是ubuntu，也可以试试ustc的[mirror](https://link.jianshu.com/?t=http%3A%2F%2Fmirrors.ustc.edu.cn%2Fkubernetes%2F)，更新比较及时。

```
cat <<EOF > /etc/apt/sources.list.d/kubernetes.list
deb http://mirrors.ustc.edu.cn/kubernetes/apt kubernetes-xenial main
EOF
```



第二种安装方式是去github:

<https://github.com/kubernetes/kubernetes>

找：[CHANGELOG-1.14.md](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.14.md)

下载Server Binaries， eg:

```
wget -q https://dl.k8s.io/v1.11.3/kubernetes-server-linux-amd64.tar.gz

[root@master tmp]# tar -zxf kubernetes-server-linux-amd64.tar.gz
[root@master tmp]# ls kubernetes
addons  kubernetes-src.tar.gz  LICENSES  server
[root@master tmp]# ls kubernetes/server/bin/ | grep -E 'kubeadm|kubelet|kubectl'
kubeadm
kubectl
kubelet

[root@master tmp]# mv kubernetes/server/bin/kube{adm,ctl,let} /usr/bin/
[root@master tmp]# ls /usr/bin/kube*
/usr/bin/kubeadm  /usr/bin/kubectl  /usr/bin/kubelet

[root@master tmp]# kubeadm version
kubeadm version: &version.Info{Major:"1", Minor:"11", GitVersion:"v1.11.3", GitCommit:"a4529464e4629c21224b3d52edfe0ea91b072862", GitTreeState:"clean", BuildDate:"2018-09-09T17:59:42Z", GoVersion:"go1.10.3", Compiler:"gc", Platform:"linux/amd64"}
[root@master tmp]# kubectl version --client
Client Version: version.Info{Major:"1", Minor:"11", GitVersion:"v1.11.3", GitCommit:"a4529464e4629c21224b3d52edfe0ea91b072862", GitTreeState:"clean", BuildDate:"2018-09-09T18:02:47Z", GoVersion:"go1.10.3", Compiler:"gc", Platform:"linux/amd64"}
[root@master tmp]# kubelet --version
Kubernetes v1.11.3
```



### 配置systemd服务

为了在生产环境中保障各组件的稳定运行，同时也为了便于管理，我们增加对 `kubelet` 的 `systemd` 的配置，由 `systemd` 对服务进行管理。

### 配置 kubelet

```
[root@master tmp]# cat <<EOF > /etc/systemd/system/kubelet.service
[Unit]
Description=kubelet: The Kubernetes Agent
Documentation=http://kubernetes.io/docs/

[Service]
ExecStart=/usr/bin/kubelet
Restart=always
StartLimitInterval=0
RestartSec=10

[Install]
WantedBy=multi-user.target
EOF
[root@master tmp]# mkdir -p /etc/systemd/system/kubelet.service.d
[root@master tmp]# cat <<EOF > /etc/systemd/system/kubelet.service.d/kubeadm.conf
[Service]
Environment="KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf"
Environment="KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml"
EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env
EnvironmentFile=-/etc/default/kubelet
ExecStart=
ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS
EOF
[root@master tmp]# systemctl enable kubelet
Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /etc/systemd/system/kubelet.service.
```

在这里我们添加了 `kubelet` 的 systemd 配置，然后添加了它的 `Drop-in` 文件，我们增加的这个 `kubeadm.conf` 文件，会被 systemd 自动解析，用于复写 `kubelet` 的基础 systemd 配置，可以看到我们增加了一系列的配置参数。在第 17 章中，我们会对 `kubelet` 做详细剖析，到时再进行解释。



### 安装 crictl 

 ln -s /root/k8s/crictl /usr/bin/crictl

<https://github.com/kubernetes-sigs/cri-tools/releases>

### 安装 socat
socat 是一款很强大的命令行工具，可以建立两个双向字节流并在其中传输数据。这么说你也许不太理解，简单点说，它其中的一个功能是可以实现端口转发。

无论在 K8S 中，还是在 Docker 中，如果我们需要在外部访问服务，端口转发是个必不可少的部分。

yum install -y socat ，

sudo apt-get install -y socat





### 拉取镜像

```sh
root@VM-0-6-ubuntu:~/k8s# kubeadm config images pull
failed to pull image "k8s.gcr.io/kube-apiserver:v1.14.0": output: Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
, error: exit status 1
# 看下 现在支持新的 版本：
[root@master131 ~]# kubeadm config images list
W0205 10:18:03.475193   13283 version.go:101] could not fetch a Kubernetes version from the internet: unable to get URL "https://dl.k8s.io/release/stable-1.txt": Get https://dl.k8s.io/release/stable-1.txt: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
W0205 10:18:03.475297   13283 version.go:102] falling back to the local client version: v1.17.2
W0205 10:18:03.475447   13283 validation.go:28] Cannot validate kube-proxy config - no validator is available
W0205 10:18:03.475457   13283 validation.go:28] Cannot validate kubelet config - no validator is available
k8s.gcr.io/kube-apiserver:v1.17.2
k8s.gcr.io/kube-controller-manager:v1.17.2
k8s.gcr.io/kube-scheduler:v1.17.2
k8s.gcr.io/kube-proxy:v1.17.2
k8s.gcr.io/pause:3.1
k8s.gcr.io/etcd:3.4.3-0
k8s.gcr.io/coredns:1.6.5

# 指定版本
root@VM-0-6-ubuntu:~/k8s# kubeadm config images list --kubernetes-version v1.14.0
k8s.gcr.io/kube-apiserver:v1.14.0
k8s.gcr.io/kube-controller-manager:v1.14.0
k8s.gcr.io/kube-scheduler:v1.14.0
k8s.gcr.io/kube-proxy:v1.14.0
k8s.gcr.io/pause:3.1
k8s.gcr.io/etcd:3.3.10
k8s.gcr.io/coredns:1.3.1
# 两种方式：
root@VM-0-6-ubuntu:~/k8s# docker pull mirrorgooglecontainers/kube-apiserver:v1.14.0
Error response from daemon: manifest for mirrorgooglecontainers/kube-apiserver:v1.14.0 not found
root@VM-0-6-ubuntu:~/k8s# docker pull registry.aliyuncs.com/google_containers/kube-apiserver:v1.14.0
v1.14.0: Pulling from google_containers/kube-apiserver
346aee5ea5bc: Pull complete
a1448280d5df: Pull complete
Digest: sha256:ebfb9018e345697e85d7adc4664c9340570bca33fff126e158264a791c6a5708
Status: Downloaded newer image for registry.aliyuncs.com/google_containers/kube-apiserver:v1.14.0
root@VM-0-6-ubuntu:~/k8s# ^C
```

后面的一样，挨个拉取。

更换名称：

```sh
root@VM-0-6-ubuntu:~/k8s# docker images
REPOSITORY                                                        TAG                 IMAGE ID            CREATED             SIZE
registry.aliyuncs.com/google_containers/kube-proxy                v1.14.0             5cd54e388aba        19 hours ago        82.1MB
registry.aliyuncs.com/google_containers/kube-controller-manager   v1.14.0             b95b1efa0436        19 hours ago        158MB
registry.aliyuncs.com/google_containers/kube-scheduler            v1.14.0             00638a24688b        19 hours ago        81.6MB
registry.aliyuncs.com/google_containers/kube-apiserver            v1.14.0             ecf910f40d6e        19 hours ago        210MB
busybox                                                           latest              d8233ab899d4        5 weeks ago         1.2MB
registry.aliyuncs.com/google_containers/coredns                   1.3.1               eb516548c180        2 months ago        40.3MB
registry.aliyuncs.com/google_containers/etcd                      3.3.10              2c4adeb21b4f        3 months ago        258MB
kindest/node                                                      v1.12.2             58eadc0ca522        4 months ago        1.5GB
registry.aliyuncs.com/google_containers/pause                     3.1                 da86e6ba6ca1        15 months ago       742kB


root@VM-0-6-ubuntu:~/k8s# docker tag registry.aliyuncs.com/google_containers/kube-proxy:v1.14.0 k8s.gcr.io/kube-proxy:v1.14.0
root@VM-0-6-ubuntu:~/k8s# docker images
REPOSITORY                                                        TAG                 IMAGE ID            CREATED             SIZE
registry.aliyuncs.com/google_containers/kube-proxy                v1.14.0             5cd54e388aba        19 hours ago        82.1MB
k8s.gcr.io/kube-proxy                                             v1.14.0             5cd54e388aba        19 hours ago        82.1MB
registry.aliyuncs.com/google_containers/kube-controller-manager   v1.14.0             b95b1efa0436        19 hours ago        158MB
registry.aliyuncs.com/google_containers/kube-scheduler            v1.14.0             00638a24688b        19 hours ago        81.6MB
registry.aliyuncs.com/google_containers/kube-apiserver            v1.14.0             ecf910f40d6e        19 hours ago        210MB
busybox                                                           latest              d8233ab899d4        5 weeks ago         1.2MB
registry.aliyuncs.com/google_containers/coredns                   1.3.1               eb516548c180        2 months ago        40.3MB
registry.aliyuncs.com/google_containers/etcd                      3.3.10              2c4adeb21b4f        3 months ago        258MB
kindest/node                                                      v1.12.2             58eadc0ca522        4 months ago        1.5GB
registry.aliyuncs.com/google_containers/pause  
```

删除无用的镜像
`docker images | grep mirrorgooglecontainers | awk '{print "docker rmi "  $1":"$2}' | sh -x`

or:

`docker images | grep google_containers | awk '{print "docker rmi "  $1":"$2}' | sh -x`



```
[root@node201 ~]# docker images
REPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE
k8s.gcr.io/kube-proxy                v1.14.2             5c24210246bb        8 months ago        82.1MB
k8s.gcr.io/kube-apiserver            v1.14.2             5eeff402b659        8 months ago        210MB
k8s.gcr.io/kube-controller-manager   v1.14.2             8be94bdae139        8 months ago        158MB
k8s.gcr.io/kube-scheduler            v1.14.2             ee18f350636d        8 months ago        81.6MB
k8s.gcr.io/etcd                      3.3.10              2c4adeb21b4f        14 months ago       258MB
k8s.gcr.io/coredns                   1.3.1               da86e6ba6ca1        2 years ago         742kB
k8s.gcr.io/pause                     3.1                 da86e6ba6ca1        2 years ago         742kB
```






### 配置kubectl

```
[root@master ~]# kubectl --kubeconfig /etc/kubernetes/admin.conf get nodes                                                
NAME      STATUS     ROLES     AGE       VERSION
master    NotReady   master    13h       v1.11.3
[root@master ~]#
[root@master ~]# KUBECONFIG=/etc/kubernetes/admin.conf kubectl get nodes                                                  
NAME      STATUS     ROLES     AGE       VERSION
master    NotReady   master    13h       v1.11.3
```

推荐方式更改默认配置文件：

```
[root@master ~]# mkdir -p $HOME/.kube
[root@master ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
[root@master ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config
[root@master ~]# kubectl get nodes                                                  
NAME      STATUS     ROLES     AGE       VERSION
master    NotReady   master    13h       v1.11.3
```





### kubeadm

初始化： kubeadm init

重置： kubeadm reset 

记得： sysctl net.bridge.bridge-nf-call-iptables=1 

用上finnal: kubeadm init --pod-network-cidr=10.244.0.0/16



#### finnal

https://github.com/coreos/flannel

使用前记得 **再配置一遍  kubectl**

1.14.0, 用的

 `kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml`

没有问题

有问题时报：

```
NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized
```





其他问题：Error from server (Forbidden)

https://github.com/coreos/flannel/issues/1103

解决方式

```

sudo kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/a70459be0084506e4ec919aa1c114638878db11b/Documentation/kube-flannel.yml
```





再次查看 Node状态：

`kubectl get nodes`

如果没有ready,看输出：

`kubectl get nodes -o yaml`



pod状态

`kubectl get pods --all-namespaces`



### join

执行和主节点一样的操作，把kubeadm init 换成 join即可。

kubeadm join 192.168.18.196:6443 --token 5z73l2.injxi65alp66le4g  --discovery-token-ca-cert-hash sha256:dd907e2f6d5dd6272d4e6394cdd2ac12f89ec6b2e7c139f868775649bc4de997

注意：

在个人搭建时，使用mac vmware 创建了一个主虚拟机master, 安装了 kubectl 等，并成功执行了 kubeadm init, 再后来，通过虚拟机的克隆功能，克隆出来两个子节点，在加入时有各种各样的问题，总结一下：

* 创建虚拟机的时候，处理器一定要选大于两核心，内存最好大于2G
* 创建一个模板虚拟机，紧紧安装了docker, 并把k8s基础镜像save到一个具体目录
* 用上方的模板去创建其他虚拟机
* 在安装kubelet 后 ， 它的服务状态是失败的，在init/join后，才会有成功状态，这点不要纠结，因为纠结在子节点加入k8s前，调节 kubelet 的状态，耽误了很长时间，其实大不了可以用忽略选项的。



#### 重填token

```

[root@localhost ~]# kubeadm token list
TOKEN                     TTL         EXPIRES                     USAGES                   DESCRIPTION                                                EXTRA GROUPS
0kqaiy.z6hq7mmjf4cny7mf   <invalid>   2019-03-29T14:40:17+08:00   authentication,signing   The default bootstrap token generated by 'kubeadm init'.   system:bootstrappers:kubeadm:default-node-token
jerycu.41sw7emsvgjgmtau   <invalid>   2019-03-30T17:06:48+08:00   authentication,signing   <none>                                                     system:bootstrappers:kubeadm:default-node-token

```



重新生成新的token:

`kubeadm token create`

获得sha256 hash 值：

```
openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'
```

eg: 
```
kubeadm join 202.182.112.120:6443 --token t14kzc.vjurhx5k98dpzqdc --discovery-token-ca-cert-hash sha256:d64f7ce1af9f9c0c73d2d737fd0095456ad98a2816cb5527d55f984c8aa8a762
```



主节点看状态：

```
kubectl get nodes
NAME            STATUS  ROLES  AGE  VERSION
192.168.18.198  ready   <none> 16h  v1.14.0
localhost       Ready   master 16h  v1.14.0
```





### 问题

#### not ready

First, describe nodes and see if it reports anything:

```
$ kubectl describe nodes
```

Look for conditions, capacity and allocatable:

```
Conditions:
  Type              Status
  ----              ------
  OutOfDisk         False
  MemoryPressure    False
  DiskPressure      False
  Ready             True
Capacity:
 cpu:       2
 memory:    2052588Ki
 pods:      110
Allocatable:
 cpu:       2
 memory:    1950188Ki
 pods:      110
```

If everything is alright here, SSH into the node and observe `kubelet` logs to see if it reports anything. Like certificate erros, authentication errors etc.

If `kubelet` is running as a systemd service, you can use

```
$ journalctl -u kubelet
```



#### host could not be reached

把自己的host改成ip

/ect/hostname 和/ect/hosts



#### CA 认证

先尝试 kubeadm reset



####  x509 cert issues after kubeadm init

```
export KUBECONFIG=/etc/kubernetes/kubelet.conf
kubectl get nodes
```



#### Error from server (Forbidden)

Error from server (Forbidden): roles.rbac.authorization.k8s.io is forbidden: User "system:node:192.168.18.196" cannot list resource "roles" in API group "rbac.authorization.k8s.io" at the cluster scope

这个问题是衔接上个问题的，

`export KUBECONFIG=/etc/kubernetes/admin.conf `

具体：<https://blog.51cto.com/foxhound/2057395?from=singlemessage>



#### It seems like the kubelet isn't running or healthy

systemctl enable docker

systemctl start docker



systemctl start kubectl

systemctl enable kubectl



reboot .   我就是这样解决的，怀疑是某些配置配置后没有重启生效。



#### The connection to the server localhost:8080 was refused

运行kubectl 相关命令时会提示refused， 我们需要像上面配置kubectl那样去配置，

但是说没有/etc/kubernetes/admin， 它 是 kubeadm init生成的。

也有说如果说是子节点需要拿父节点的配置：

<https://github.com/kubernetes/kubernetes/issues/50295>





#### kubeadm reset 卡住

基本卡住在[reset] unmounting mounted directories in "/var/lib/kubelet"

Ctrl + c, 

systemctl restart docker.service

再试



#### [ERROR FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]

在 kubeadm join 或者 kubeadm init 的时候：

``` 
[preflight] Running pre-flight checks
error execution phase preflight: [preflight] Some fatal errors occurred:
	[ERROR FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]: /proc/sys/net/bridge/bridge-nf-call-iptables contents are not set to 1
	[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1
[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...
```

解决： echo "1" >/proc/sys/net/bridge/bridge-nf-call-iptables

或者：sysctl net.bridge.bridge-nf-call-iptables=1 



#### [ERROR FileContent--proc-sys-net-ipv4-ip_forward]

echo 1 > /proc/sys/net/ipv4/ip_forward